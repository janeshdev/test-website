---
title: Machine learning Cards from Twitter in R
author: ~
date: '2017-12-20'
slug: machine-learning-cards-from-twitter-in-r
categories: []
tags: []
---



<p>I have been following Chris Albon on Twitter and have seen some really nice looking machine learning cards on his Twitter. While one can go to his <a href="http://machinelearningflashcards.com">website</a> and buy all the cards he has produced. However, I was curious to see if I could download those flash cards in R. So, I started looking for a R package that would help to download the tweets by Chris Albon. I ended up using <code>rtweet</code> package for my analysis.</p>
<p>The libraries that I would be using for this analysis are as follows:</p>
<ul>
<li>rtweet : To import the tweets from Twitter to R.</li>
<li>dplyr : To do manipulation of tweets</li>
<li>rvest : To extract the information from web data</li>
</ul>
<p>Let’s get started with <code>rtweet</code> package. First I am going to search for the tweets from Chris Albon.</p>
<pre class="r"><code># Load Libraries
library(rtweet)
library(dplyr)</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>library(rvest)</code></pre>
<pre><code>## Loading required package: xml2</code></pre>
<div id="rtweet-package-usage" class="section level3">
<h3>rtweet package usage</h3>
<p>I am going to use <code>search_tweets</code> function in <code>rtweet</code> package to find the tweets.</p>
<pre class="r"><code>albon &lt;- rtweet::search_tweets(q = &quot;chrisalbon&quot;, include_rts = FALSE,retryonratelimit = TRUE, n = 18000)</code></pre>
<pre><code>## Searching for tweets...</code></pre>
<pre><code>## This may take a few seconds...</code></pre>
<pre><code>## Finished collecting tweets!</code></pre>
<pre class="r"><code># Look at head of albon dataframe
head(albon)</code></pre>
<pre><code>## # A tibble: 6 x 68
##            status_id          created_at    user_id  screen_name
##                &lt;chr&gt;              &lt;dttm&gt;      &lt;chr&gt;        &lt;chr&gt;
## 1 943732332824969216 2017-12-21 06:38:16  473718208      SHiggan
## 2 943732329226305536 2017-12-21 06:38:15    6024272 sergeimuller
## 3 943732314663776257 2017-12-21 06:38:12   19340488      jortheo
## 4 943730962243862528 2017-12-21 06:32:49 2990872965     SETIEric
## 5 943729686881996800 2017-12-21 06:27:45  614046734    jdparaujo
## 6 943727710685163520 2017-12-21 06:19:54   14643231    alanmimms
## # ... with 64 more variables: text &lt;chr&gt;, source &lt;chr&gt;,
## #   display_text_width &lt;dbl&gt;, reply_to_status_id &lt;chr&gt;,
## #   reply_to_user_id &lt;chr&gt;, reply_to_screen_name &lt;chr&gt;, is_quote &lt;lgl&gt;,
## #   is_retweet &lt;lgl&gt;, favorite_count &lt;int&gt;, retweet_count &lt;int&gt;,
## #   hashtags &lt;list&gt;, symbols &lt;list&gt;, urls_url &lt;list&gt;, urls_t.co &lt;list&gt;,
## #   urls_expanded_url &lt;list&gt;, media_url &lt;list&gt;, media_t.co &lt;list&gt;,
## #   media_expanded_url &lt;list&gt;, media_type &lt;list&gt;, ext_media_url &lt;list&gt;,
## #   ext_media_t.co &lt;list&gt;, ext_media_expanded_url &lt;list&gt;,
## #   ext_media_type &lt;chr&gt;, mentions_user_id &lt;list&gt;,
## #   mentions_screen_name &lt;list&gt;, lang &lt;chr&gt;, quoted_status_id &lt;chr&gt;,
## #   quoted_text &lt;chr&gt;, quoted_created_at &lt;dttm&gt;, quoted_source &lt;chr&gt;,
## #   quoted_favorite_count &lt;int&gt;, quoted_retweet_count &lt;int&gt;,
## #   quoted_user_id &lt;chr&gt;, quoted_screen_name &lt;chr&gt;, quoted_name &lt;chr&gt;,
## #   quoted_followers_count &lt;int&gt;, quoted_friends_count &lt;int&gt;,
## #   quoted_statuses_count &lt;int&gt;, quoted_location &lt;chr&gt;,
## #   quoted_description &lt;chr&gt;, quoted_verified &lt;lgl&gt;,
## #   retweet_status_id &lt;chr&gt;, retweet_text &lt;chr&gt;,
## #   retweet_created_at &lt;dttm&gt;, retweet_source &lt;chr&gt;,
## #   retweet_favorite_count &lt;int&gt;, retweet_user_id &lt;chr&gt;,
## #   retweet_screen_name &lt;chr&gt;, retweet_name &lt;chr&gt;,
## #   retweet_followers_count &lt;int&gt;, retweet_friends_count &lt;int&gt;,
## #   retweet_statuses_count &lt;int&gt;, retweet_location &lt;chr&gt;,
## #   retweet_description &lt;chr&gt;, retweet_verified &lt;lgl&gt;, place_url &lt;chr&gt;,
## #   place_name &lt;chr&gt;, place_full_name &lt;chr&gt;, place_type &lt;chr&gt;,
## #   country &lt;chr&gt;, country_code &lt;chr&gt;, geo_coords &lt;list&gt;,
## #   coords_coords &lt;list&gt;, bbox_coords &lt;list&gt;</code></pre>
<pre class="r"><code>dim(albon)</code></pre>
<pre><code>## [1] 2100   68</code></pre>
<pre class="r"><code># We could also use the following but I wanted to see the tweets from Chris Albon
# albon1 &lt;- rtweet::search_tweets(q = &quot;machinelearningflashcards.com&quot;, 
#                                 include_rts = FALSE, 
#                                 retryonratelimit = TRUE)</code></pre>
<p>We have got a tibble with 2000 observations and 68 columns. Now, let’s look at the actual tweets. We will be looking at the column <code>text</code> as it has the text of the tweet.</p>
<pre class="r"><code># Text of tweet
albon[, &quot;text&quot;]</code></pre>
<pre><code>## # A tibble: 2,100 x 1
##                                                                                  text
##                                                                                 &lt;chr&gt;
##  1        @chrisalbon ..... for the love of god.. we tried, but the client escalated 
##  2 &quot;@chrisalbon \xf0\u009f\u0091\u008d\xf0\u009f\u008f&lt;U+00BE&gt; my company has a code 
##  3                                                   Wise man https://t.co/eGpk9gjuZ9
##  4                                    Been there.  Done that. https://t.co/FNd21DZD8y
##  5        &quot;When you have to work from your significant others old bedroom \xf0\u009f
##  6                                                 @chrisalbon Been there. Done that.
##  7                                      &quot;@chrisalbon Too late \xf0\u009f\u0098\u008a&quot;
##  8                                @chrisalbon @MystyVander We deployed last night tho
##  9        @chrisalbon Pelican. Hugo is pretty nice too, but I only use it with Rs bl
## 10        or deploy and artfully walk away from that spouse &amp;amp; racist uncle https:
## # ... with 2,090 more rows</code></pre>
<p>We are interested in the tweets that has images and url <code>machinelearningcards.com</code>. You will notice that all the images / links in Twitter are renamed with the prefix “<a href="https://t.co/" class="uri">https://t.co/</a>”. After some observations, I found out that twitter renamed the website <code>machinelearningflashcards.com</code> as <code>https://t.co/eZ2bbpDzwV</code>. So, let’s use this link as our pattern and find the tweets that has the link. We are going to use <code>grep</code> function to find the pattern in the <code>text</code> column.</p>
<pre class="r"><code>pattern &lt;- &quot;https://t.co/eZ2bbpDzwV&quot;
# Create a new dataframe with only text as the column
machine_learning &lt;- albon[grep(pattern, albon[,&quot;text&quot;] %&gt;% .$text), &quot;text&quot;]
machine_learning</code></pre>
<pre><code>## # A tibble: 16 x 1
##                                                                           text
##                                                                          &lt;chr&gt;
##  1 SVC Radial Basis Function Kernel https://t.co/eZ2bbpDzwV https://t.co/l8Zhh
##  2             Standardization https://t.co/eZ2bbpDzwV https://t.co/sfZ4tOamRv
##  3          Adjusted R-Squared https://t.co/eZ2bbpDzwV https://t.co/fNzk1xC8Pn
##  4               Weak Learners https://t.co/eZ2bbpDzwV https://t.co/D0LSHzlJ3m
##  5        Total Sum-Of-Squares https://t.co/eZ2bbpDzwV https://t.co/ROQxeKKEbb
##  6 Sigmoid Activation Function https://t.co/eZ2bbpDzwV https://t.co/HW3haErLxn
##  7                    Boosting https://t.co/eZ2bbpDzwV https://t.co/4X3NOqLuKT
##  8            Interaction Term https://t.co/eZ2bbpDzwV https://t.co/8fokl8KJfh
##  9                  Hinge Loss https://t.co/eZ2bbpDzwV https://t.co/C0gFuRQnt6
## 10            One-Hot Encoding https://t.co/eZ2bbpDzwV https://t.co/jd2yOf8p5c
## 11   Issues With Platt Scaling https://t.co/eZ2bbpDzwV https://t.co/ziGuhNBycz
## 12               Interpolation https://t.co/eZ2bbpDzwV https://t.co/qZzIZIdyNx
## 13                Determinants https://t.co/eZ2bbpDzwV https://t.co/jTABNspxZz
## 14          Standard Deviation https://t.co/eZ2bbpDzwV https://t.co/Kf4YBHcbV3
## 15          Manhattan Distance https://t.co/eZ2bbpDzwV https://t.co/S3IahqLsBz
## 16                  Notation 4 https://t.co/eZ2bbpDzwV https://t.co/NZsUMwGGr5</code></pre>
<p>After some manipulation, we have found 16 tweets that has machine learning terminology, website link, and the flash card image link. As you can see in all the tweets above, the first link is the website link and the last link is the image link.</p>
<p>If we try to download the image link, R will download the html document. We will have to process these links a little so we can download all the images directly from R.</p>
</div>
<div id="separate-terminology-and-image-links" class="section level3">
<h3>Separate terminology and image links</h3>
<pre class="r"><code># Flash Card URL as url column 
machine_learning$url &lt;- lapply(
  1:nrow(machine_learning), 
  FUN = function(x)
    tail(strsplit(
      machine_learning$text[x], split = &quot; &quot;)
      [[1]],
      n = 1)
) %&gt;%
  as.character()

# Machine learning terminology as name Column
machine_learning$name &lt;- lapply(1:nrow(machine_learning), function(x)
  gsub(
    x = machine_learning$text[x],
    pattern = &quot;https://.+&quot;, replacement = &quot;&quot;
  )) %&gt;%
  as.character()

machine_learning[, c(&quot;url&quot;, &quot;name&quot;)]</code></pre>
<pre><code>## # A tibble: 16 x 2
##                        url                              name
##                      &lt;chr&gt;                             &lt;chr&gt;
##  1 https://t.co/l8ZhhzAytA SVC Radial Basis Function Kernel 
##  2 https://t.co/sfZ4tOamRv                  Standardization 
##  3 https://t.co/fNzk1xC8Pn               Adjusted R-Squared 
##  4 https://t.co/D0LSHzlJ3m                    Weak Learners 
##  5 https://t.co/ROQxeKKEbb             Total Sum-Of-Squares 
##  6 https://t.co/HW3haErLxn      Sigmoid Activation Function 
##  7 https://t.co/4X3NOqLuKT                         Boosting 
##  8 https://t.co/8fokl8KJfh                 Interaction Term 
##  9 https://t.co/C0gFuRQnt6                       Hinge Loss 
## 10 https://t.co/jd2yOf8p5c                 One-Hot Encoding 
## 11 https://t.co/ziGuhNBycz        Issues With Platt Scaling 
## 12 https://t.co/qZzIZIdyNx                    Interpolation 
## 13 https://t.co/jTABNspxZz                     Determinants 
## 14 https://t.co/Kf4YBHcbV3               Standard Deviation 
## 15 https://t.co/S3IahqLsBz               Manhattan Distance 
## 16 https://t.co/NZsUMwGGr5                       Notation 4</code></pre>
<p>We have now separated the terminology and image links. When we will be saving the image we will use text in column <code>name</code> as the name of the flash card image.</p>
</div>
<div id="use-of-rvest-package-to-extract-info-from-link" class="section level3">
<h3>Use of rvest package to extract info from link</h3>
<p>While we have separated the link that contains the link of the image, the actual link that can be used to download image needs to be extracted from html of the pages.</p>
<p>Let us use the link <code>https://t.co/l8ZhhzAytA</code> from the above data frame to extract the link.</p>
<pre class="r"><code>url &lt;- &quot;https://t.co/l8ZhhzAytA&quot;
url %&gt;% 
  read_html() %&gt;% 
  rvest::html_nodes(&#39;div.js-adaptive-photo&#39;) %&gt;% 
  as.character()</code></pre>
<pre><code>## [1] &quot;&lt;div class=\&quot;AdaptiveMedia-photoContainer js-adaptive-photo \&quot; data-image-url=\&quot;https://pbs.twimg.com/media/DRg-8nNUMAAh7_g.png\&quot; data-element-context=\&quot;platform_photo_card\&quot; style=\&quot;background-color:rgba(64,47,59,1.0);\&quot; data-dominant-color=\&quot;[64,47,59]\&quot;&gt;\n  &lt;img data-aria-label-part src=\&quot;https://pbs.twimg.com/media/DRg-8nNUMAAh7_g.png\&quot; alt=\&quot;\&quot; style=\&quot;width: 100%; top: -0px;\&quot;&gt;\n&lt;/div&gt;&quot;</code></pre>
<p>From the output above, we can see the link <code>https://pbs.twimg.com/media/DRg-8nNUMAAh7_g.png</code>. This is the link we will be using to download the flash card. We want to process it nicely so that we could use the same approach for all the 16 cards. Let’s extract only the image link.</p>
<pre class="r"><code>url %&gt;% 
  read_html() %&gt;% 
  rvest::html_nodes(&#39;div.js-adaptive-photo&#39;) %&gt;% 
  as.character() %&gt;%
strsplit(split = &quot;\\ &quot;) %&gt;% 
     unlist() </code></pre>
<pre><code>##  [1] &quot;&lt;div&quot;                                                              
##  [2] &quot;class=\&quot;AdaptiveMedia-photoContainer&quot;                              
##  [3] &quot;js-adaptive-photo&quot;                                                 
##  [4] &quot;\&quot;&quot;                                                                
##  [5] &quot;data-image-url=\&quot;https://pbs.twimg.com/media/DRg-8nNUMAAh7_g.png\&quot;&quot;
##  [6] &quot;data-element-context=\&quot;platform_photo_card\&quot;&quot;                      
##  [7] &quot;style=\&quot;background-color:rgba(64,47,59,1.0);\&quot;&quot;                    
##  [8] &quot;data-dominant-color=\&quot;[64,47,59]\&quot;&gt;\n&quot;                             
##  [9] &quot;&quot;                                                                  
## [10] &quot;&lt;img&quot;                                                              
## [11] &quot;data-aria-label-part&quot;                                              
## [12] &quot;src=\&quot;https://pbs.twimg.com/media/DRg-8nNUMAAh7_g.png\&quot;&quot;           
## [13] &quot;alt=\&quot;\&quot;&quot;                                                          
## [14] &quot;style=\&quot;width:&quot;                                                    
## [15] &quot;100%;&quot;                                                             
## [16] &quot;top:&quot;                                                              
## [17] &quot;-0px;\&quot;&gt;\n&lt;/div&gt;&quot;</code></pre>
<p>From the output above, we can see that there are two elements <code>5</code> and <code>12</code> that has the image download link that we are interested. I am going to use the 5th element to extract the link. The complete code for the url we chose is as follows:</p>
<pre class="r"><code>url %&gt;% 
  read_html() %&gt;% 
  rvest::html_nodes(&#39;div.js-adaptive-photo&#39;) %&gt;% 
  as.character() %&gt;%
strsplit(split = &quot;\\ &quot;) %&gt;% 
     unlist() %&gt;% 
    .[5] %&gt;%
    gsub(pattern = &quot;data-image-url&quot;, replacement = &quot;&quot;) %&gt;%
    gsub(pattern = &quot;\\=&quot;, replacement = &quot;&quot;) %&gt;%
    gsub(pattern = &#39;\&quot;&#39;, replacement = &quot;&quot;)</code></pre>
<pre><code>## [1] &quot;https://pbs.twimg.com/media/DRg-8nNUMAAh7_g.png&quot;</code></pre>
<p>We got the link that we were looking for.</p>
</div>
<div id="extracting-image-links-for-all-elements" class="section level3">
<h3>Extracting image links for all elements</h3>
<p>We figured out how to extract the link for 1 instance. Let’s use the R <code>sapply</code> function and generalize the above procedure and write a code to download all 16 images.</p>
<pre class="r"><code># Use rvest to process the image
sapply(1:nrow(machine_learning), function(x) 
  machine_learning$url[x] %&gt;% 
    as.character() %&gt;%
    # Read URL using rvest function read_html
    xml2::read_html() %&gt;% 
    rvest::html_nodes(&#39;div.js-adaptive-photo&#39;) %&gt;% 
    as.character() %&gt;% 
    strsplit(split = &quot;\\ &quot;) %&gt;% 
    unlist() %&gt;% 
    .[5] %&gt;% 
    gsub(pattern = &quot;data-image-url&quot;, replacement = &quot;&quot;) %&gt;% 
    gsub(pattern = &quot;\\=&quot;, replacement = &quot;&quot;) %&gt;% 
    gsub(pattern = &#39;\&quot;&#39;, replacement = &quot;&quot;) %&gt;% 
    download.file(destfile = paste0(
      &quot;machine_learning/&quot;,machine_learning$name[x], &quot;.png&quot;
    ), mode = &#39;wb&#39;))</code></pre>
<p>I will have to do some research to find out previous flash cards. He might have posted the images without the link to his website.</p>
</div>
